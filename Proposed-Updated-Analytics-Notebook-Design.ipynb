{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25999cae",
   "metadata": {},
   "source": [
    "# FRESCO Analytics Notebook\n",
    "### Overview\n",
    "This notebook has been designed to make analysis of the Anvil dataset as easy as possible. Generally speaking, it will allow the user to access the Anvil files stored locally, select a number of analysis options, and view the results.\n",
    "\n",
    "The notebook can be divided into three sections:\n",
    "#### Section 1: Data Filtering\n",
    "This initial section is your gateway to defining the precise scope of your analysis. Select a specific datetime window and apply various filters to customize your dataset to your needs.\n",
    "\n",
    "#### Section 2: Data Analysis Options\n",
    "The second section provides a suite of analysis options. Here, you have the liberty to pick and choose the analysis that fits your needs.\n",
    "\n",
    "#### Section 3: Data Analysis and Visualizations\n",
    "The final section of this notebook performs the selected analysis option on the filtered dataset, and provides visualizations of those analyses.\n",
    "\n",
    "### Step-by-Step Instructions\n",
    "1. **Cell 1:** Start by defining the temporal boundaries of your dataset. This time frame will dictate the extraction of relevant host time series and job accounting data from the database.\n",
    "2. **Cell 2:** Here, choose your preferred preprocessing methods. Multiple methods can be combined.\n",
    "3. **Cell 3:** Specify the units for the time series data of the host that you wish to be included in the analysis.\n",
    "4. **Cell 4:** Here, you input your desired values and select options. **Remember:** If units were selected in step 3, ensure the low and high values are added here, and click the **\"Save Values\"** button before moving forward.\n",
    "5. **Cell 5:** This step involves two actions:\n",
    "- Download Option: You can choose to download the filtered dataset for offline use or further analysis.\n",
    "- Analysis Selection: Choose from various data analysis options for your filtered dataset.\n",
    "6. **Cell 6:** Running this cell will generate all the data visualizations. If you would like to explore correlations among metrics and statistics, select from the provided options.\n",
    "7. **Cell 7:** Run to see correlations.\n",
    "8. **Cell 8:** TBD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814c04de",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-30T18:02:22.283222200Z",
     "start_time": "2023-07-30T18:02:17.824036100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide a time window for your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": "DatePicker(value=None, description='Pick a Date', step=1)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ed5275663104670bb73e231792c4b6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "DatePicker(value=None, description='Pick a Date', step=1)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e6d81f3b1f54428a1350cca9b196906"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Button(description='Validate Dates', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e3e2c20c7bf48bc8133ada5cd687f34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Output()",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b7beb8d47014c96863648ab194e131b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing: select one or many:\n"
     ]
    },
    {
     "data": {
      "text/plain": "SelectMultiple(description='Options:', index=(0,), options=('None', 'Remove Rows with Missing Metric', 'Remove…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8814d199f5d4f80a1642ff486b374fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------- CELL 1 --------------\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import notebook_functions as nbf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(r\"Please provide a time window for your dataset.\")\n",
    "\n",
    "# ************* REMOVE WHEN DONE WITH DEV ******************************\n",
    "start_time = widgets.DatePicker(\n",
    "    description='Pick a Date',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "end_time = widgets.DatePicker(\n",
    "    description='Pick a Date',\n",
    "    disabled=False\n",
    ")\n",
    "# ************* REMOVE WHEN DONE WITH DEV ******************************\n",
    "\n",
    "# start_time = widgets.NaiveDatetimePicker(\n",
    "#     value=datetime.now().replace(microsecond=0),\n",
    "#     placeholder='',\n",
    "#     description='Start Time:',\n",
    "#     disabled=False\n",
    "# )\n",
    "#\n",
    "# end_time = widgets.NaiveDatetimePicker(\n",
    "#     value=datetime.now().replace(microsecond=0),\n",
    "#     placeholder='',\n",
    "#     description='End Time:',\n",
    "#     disabled=False\n",
    "# )\n",
    "\n",
    "# Add a button that the user can press to validate the dates\n",
    "validate_button = widgets.Button(description=\"Validate Dates\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if end_time.value and start_time.value >= end_time.value:\n",
    "            print(\"Error: Start Time should be less than End Time\")\n",
    "        elif start_time.value and end_time.value <= start_time.value:\n",
    "            print(\"Error: End Time should be greater than Start Time\")\n",
    "        else:\n",
    "            print(\"Time range is valid\")\n",
    "\n",
    "validate_button.on_click(on_button_clicked)\n",
    "\n",
    "display(start_time, end_time, validate_button, output)\n",
    "\n",
    "print(\"Data preprocessing: select one or many:\")\n",
    "preprocessing = widgets.SelectMultiple(\n",
    "    options=['None', 'Remove Rows with Missing Metric', 'Remove Rows with Negative Value', 'Add an Interval Column'],\n",
    "    value=['None'],\n",
    "    description='Options:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2bb83db",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-30T18:04:28.734324600Z",
     "start_time": "2023-07-30T18:03:05.197106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME SERIES\n",
      "                             time     host         jid  type    event   unit  \\\n",
      "0       2023-04-07 00:00:02-06:00  NODE887  JOB1166619  None  memused     GB   \n",
      "1       2023-04-07 00:01:02-06:00  NODE887  JOB1166619  None  memused     GB   \n",
      "2       2023-04-07 00:02:02-06:00  NODE887  JOB1166619  None  memused     GB   \n",
      "3       2023-04-07 00:03:02-06:00  NODE887  JOB1166619  None  memused     GB   \n",
      "4       2023-04-07 00:04:02-06:00  NODE887  JOB1166619  None  memused     GB   \n",
      "...                           ...      ...         ...   ...      ...    ...   \n",
      "1038728 2023-04-07 00:07:02-06:00  NODE887  JOB1166619  None  cpuuser  CPU %   \n",
      "1038729 2023-04-07 00:08:02-06:00  NODE887  JOB1166619  None  cpuuser  CPU %   \n",
      "1038730 2023-04-07 00:09:02-06:00  NODE887  JOB1166619  None  cpuuser  CPU %   \n",
      "1038731 2023-04-07 00:10:02-06:00  NODE887  JOB1166619  None  cpuuser  CPU %   \n",
      "1038732 2023-04-07 00:11:02-06:00  NODE887  JOB1166619  None  cpuuser  CPU %   \n",
      "\n",
      "             value  diff   arc  \n",
      "0        51.791985  None  None  \n",
      "1        51.628080  None  None  \n",
      "2        51.936820  None  None  \n",
      "3        52.123300  None  None  \n",
      "4        51.953163  None  None  \n",
      "...            ...   ...   ...  \n",
      "1038728  59.814330  None  None  \n",
      "1038729  58.737720  None  None  \n",
      "1038730  59.608215  None  None  \n",
      "1038731  60.341618  None  None  \n",
      "1038732  61.450924  None  None  \n",
      "\n",
      "[1038733 rows x 9 columns]\n",
      "ACCOUNT LOG\n",
      "             jid               submit_time                start_time  \\\n",
      "0     JOB1160235 2023-04-07 23:37:38-06:00 2023-04-07 23:37:38-06:00   \n",
      "1     JOB1160236 2023-04-07 21:17:11-06:00 2023-04-07 21:17:37-06:00   \n",
      "2     JOB1160237 2023-04-07 20:29:28-06:00 2023-04-07 20:29:37-06:00   \n",
      "3     JOB1160238 2023-04-07 13:56:07-06:00 2023-04-07 13:56:34-06:00   \n",
      "4     JOB1160239 2023-04-07 17:22:22-06:00 2023-04-07 17:23:34-06:00   \n",
      "...          ...                       ...                       ...   \n",
      "6085  JOB1166604 2023-04-07 00:18:15-06:00 2023-04-07 00:18:15-06:00   \n",
      "6086  JOB1166605 2023-04-07 00:18:15-06:00 2023-04-07 00:18:15-06:00   \n",
      "6087  JOB1166606 2023-04-07 00:18:15-06:00 2023-04-07 00:18:15-06:00   \n",
      "6088  JOB1166607 2023-04-07 00:18:15-06:00 2023-04-07 00:18:15-06:00   \n",
      "6089  JOB1166608 2023-04-07 00:18:15-06:00 2023-04-07 00:18:15-06:00   \n",
      "\n",
      "                      end_time runtime  timelimit node_hrs  nhosts  ncores  \\\n",
      "0    2023-04-07 23:59:37-06:00    None     7200.0     None       1      25   \n",
      "1    2023-04-07 23:57:07-06:00    None    10800.0     None       1       2   \n",
      "2    2023-04-07 23:56:42-06:00    None   345600.0     None       1      10   \n",
      "3    2023-04-07 23:56:39-06:00    None    36000.0     None      16    2048   \n",
      "4    2023-04-07 23:56:00-06:00    None   345600.0     None       1     128   \n",
      "...                        ...     ...        ...      ...     ...     ...   \n",
      "6085 2023-04-07 00:20:09-06:00    None    14400.0     None       1       4   \n",
      "6086 2023-04-07 00:20:07-06:00    None    14400.0     None       1       4   \n",
      "6087 2023-04-07 00:20:05-06:00    None    14400.0     None       1       4   \n",
      "6088 2023-04-07 00:20:05-06:00    None    14400.0     None       1       4   \n",
      "6089 2023-04-07 00:19:56-06:00    None    14400.0     None       1       4   \n",
      "\n",
      "      ngpus  username   account     queue state        jobname   exitcode  \\\n",
      "0         0   USER849   GROUP33    shared  None      JOBNAME80  CANCELLED   \n",
      "1         0  USER1495   GROUP33    shared  None      JOBNAME80  CANCELLED   \n",
      "2         0  USER1936  GROUP206    shared  None  JOBNAME217720  COMPLETED   \n",
      "3         0  USER1885  GROUP198      wide  None     JOBNAME822    TIMEOUT   \n",
      "4         0    USER21   GROUP81  standard  None  JOBNAME261231  COMPLETED   \n",
      "...     ...       ...       ...       ...   ...            ...        ...   \n",
      "6085      0  USER1936  GROUP206    shared  None  JOBNAME148744  COMPLETED   \n",
      "6086      0  USER1936  GROUP206    shared  None  JOBNAME108656  COMPLETED   \n",
      "6087      0  USER1936  GROUP206    shared  None  JOBNAME148797  COMPLETED   \n",
      "6088      0  USER1936  GROUP206    shared  None  JOBNAME148803  COMPLETED   \n",
      "6089      0  USER1936  GROUP206    shared  None  JOBNAME294344  COMPLETED   \n",
      "\n",
      "                                              host_list  \n",
      "0                                             [NODE902]  \n",
      "1                                             [NODE406]  \n",
      "2                                             [NODE918]  \n",
      "3     [NODE68, NODE69, NODE160, NODE131, NODE33, NOD...  \n",
      "4                                             [NODE224]  \n",
      "...                                                 ...  \n",
      "6085                                          [NODE887]  \n",
      "6086                                          [NODE912]  \n",
      "6087                                          [NODE912]  \n",
      "6088                                          [NODE912]  \n",
      "6089                                          [NODE912]  \n",
      "\n",
      "[6090 rows x 17 columns]\n",
      "Optional: select the units to be included in the timeseries data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "SelectMultiple(description='Units:', index=(0,), options=('None', 'CPU %', 'GPU %', 'GB:memused', 'GB:memused_…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23f8e2252a854f5ebb7711bd0a9e9a44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------- CELL 2 --------------\n",
    "\n",
    "# get timeseries from the DB\n",
    "time_series_df = nbf.get_time_series_from_database(start_time.value.strftime('%Y-%m-%d %H:%M:%S'), end_time.value.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# get the account logs from the DB\n",
    "account_log_df = nbf.get_account_log_from_database(start_time.value.strftime('%Y-%m-%d %H:%M:%S'), end_time.value.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "print(\"TIME SERIES\")\n",
    "print(time_series_df)\n",
    "print(\"ACCOUNT LOG\")\n",
    "print(account_log_df)\n",
    "\n",
    "# do the preprocessing\n",
    "for value in preprocessing.value:\n",
    "    if \"Missing Metric\" in value:\n",
    "        time_series_df = time_series_df.dropna()\n",
    "    if \"Add\" in value:\n",
    "        time_series_df = nbf.add_interval_column(end_time.value, time_series_df)\n",
    "    if \"Negative Value\" in value:\n",
    "        time_series_df = time_series_df[time_series_df['Value'] >= 0]\n",
    "\n",
    "print(\"Optional: select the units to be included in the timeseries data.\")\n",
    "units = widgets.SelectMultiple(\n",
    "    options=['None', 'CPU %', 'GPU %', 'GB:memused', 'GB:memused_minus_diskcache', 'GB/s', 'MB/s'],\n",
    "    value=['None'],\n",
    "    description='Units:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1cb487b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-30T18:04:57.631244500Z",
     "start_time": "2023-07-30T18:04:57.392051200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(FloatRangeSlider(value=(0.01, 99.99), description='CPU % Range:', layout=Layout(width='99%'), r…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f27e86d1b30540539c7e26bf89e36fd5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Button(description='Save Values', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6af4f48f4b304a55be8a8cc7959e1daa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(FloatRangeSlider(value=(0.01, 99.99), description='MB/s Range:', layout=Layout(width='99%'), re…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4278171a5fc24d0ab8e8024d9189f4dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Button(description='Save Values', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f2dd7b3418d446aa4da3ee8a54468f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional: provide the hosts to be included in the timeseries data e.g., 'NODE1, NODE2'\n"
     ]
    },
    {
     "data": {
      "text/plain": "Text(value='', description='Hosts:', placeholder='')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30b2512b57214dda9d6a46a3f7eaf027"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional: provide the jobs to be included in the timeseries data e.g., 'JOB1, JOB2'\n"
     ]
    },
    {
     "data": {
      "text/plain": "Text(value='', description='Jobs:', placeholder='')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d5b25c3c7204c519cc9165539858bd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional: select if you want the account logs to be returned for the Job IDs matching your query.\n"
     ]
    },
    {
     "data": {
      "text/plain": "ToggleButton(value=False, description='Account Logs', icon='check', tooltip='Return Account Logs?')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e53a8a20f0d496aa3a50fd1b6b2fd59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional: select the columns to be included in the timeseries data (hold control to select multiple). If no columns are selected, all columns will be included.\n"
     ]
    },
    {
     "data": {
      "text/plain": "SelectMultiple(description='Return Columns', index=(0,), options=('None', 'Job Id', 'Hosts', 'Events', 'Units'…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2d8961912c346898bcdbfdf401a45c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------- CELL 3 --------------\n",
    "\n",
    "unit_values = {}  # stores user low and high value user input such that: key = a unit from the units list above /// value = (low_value, high_value)\n",
    "\n",
    "for value in units.value:\n",
    "    if value != 'None':\n",
    "        nbf.setup_widgets(unit_values, value)\n",
    "\n",
    "print(\"Optional: provide the hosts to be included in the timeseries data e.g., 'NODE1, NODE2'\")\n",
    "hosts = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='Hosts:',\n",
    "    disabled=False\n",
    ")\n",
    "display(hosts)\n",
    "print(\"Optional: provide the jobs to be included in the timeseries data e.g., 'JOB1, JOB2'\")\n",
    "job_ids = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='Jobs:',\n",
    "    disabled=False\n",
    ")\n",
    "display(job_ids)\n",
    "\n",
    "print(\"Optional: select if you want the account logs to be returned for the Job IDs matching your query.\")\n",
    "return_account_logs = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Account Logs',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Return Account Logs?',\n",
    "    icon='check'\n",
    ")\n",
    "display(return_account_logs)\n",
    "\n",
    "print(\"Optional: select the columns to be included in the timeseries data (hold control to select multiple). If no columns are \"\n",
    "      \"selected, all columns will be included. ** NOTE ** if 'Units', 'Values', and 'Timestamps' are required for graphing in the cells below!\")\n",
    "timeseries_return_columns = widgets.SelectMultiple(\n",
    "    options=['None', 'Job Id', 'Hosts', 'Events', 'Units', 'Values', 'Timestamps'],\n",
    "    value=['None'],\n",
    "    description='Return Columns',\n",
    "    disabled=False\n",
    ")\n",
    "display(timeseries_return_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f5b1281",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-30T18:13:57.446629400Z",
     "start_time": "2023-07-30T18:13:56.133876600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering Dataframe for CPU %. . .\n",
      "Filtering Dataframe for MB/s. . .\n",
      "PRINTING FILTERED RESULTS:\n",
      "TIME SERIES\n",
      "          unit      value                      time\n",
      "131      CPU %  73.481040 2023-04-07 00:00:02-06:00\n",
      "132      CPU %  73.780570 2023-04-07 00:01:02-06:00\n",
      "133      CPU %  73.847030 2023-04-07 00:02:02-06:00\n",
      "134      CPU %  73.797160 2023-04-07 00:03:02-06:00\n",
      "135      CPU %  73.774994 2023-04-07 00:04:02-06:00\n",
      "...        ...        ...                       ...\n",
      "1035359   MB/s  10.174463 2023-04-07 00:21:02-06:00\n",
      "1035563   MB/s   9.335039 2023-04-07 00:20:02-06:00\n",
      "1035564   MB/s  10.174463 2023-04-07 00:21:02-06:00\n",
      "1038324   MB/s  15.915777 2023-04-07 00:10:02-06:00\n",
      "1038364   MB/s  15.915777 2023-04-07 00:10:02-06:00\n",
      "\n",
      "[140079 rows x 3 columns]\n",
      "ACCOUNT LOG\n",
      "             jid               submit_time                start_time  \\\n",
      "1     JOB1160236 2023-04-07 21:17:11-06:00 2023-04-07 21:17:37-06:00   \n",
      "2     JOB1160237 2023-04-07 20:29:28-06:00 2023-04-07 20:29:37-06:00   \n",
      "3     JOB1160238 2023-04-07 13:56:07-06:00 2023-04-07 13:56:34-06:00   \n",
      "4     JOB1160239 2023-04-07 17:22:22-06:00 2023-04-07 17:23:34-06:00   \n",
      "6     JOB1160241 2023-04-07 20:55:29-06:00 2023-04-07 20:55:37-06:00   \n",
      "...          ...                       ...                       ...   \n",
      "6067  JOB1166576 2023-04-07 00:33:49-06:00 2023-04-07 00:33:50-06:00   \n",
      "6068  JOB1166578 2023-04-07 00:49:44-06:00 2023-04-07 00:50:01-06:00   \n",
      "6071  JOB1166583 2023-04-07 00:28:58-06:00 2023-04-07 00:29:17-06:00   \n",
      "6072  JOB1166589 2023-04-07 00:18:15-06:00 2023-04-07 00:18:15-06:00   \n",
      "6073  JOB1166591 2023-04-07 00:18:15-06:00 2023-04-07 00:18:15-06:00   \n",
      "\n",
      "                      end_time runtime  timelimit node_hrs  nhosts  ncores  \\\n",
      "1    2023-04-07 23:57:07-06:00    None    10800.0     None       1       2   \n",
      "2    2023-04-07 23:56:42-06:00    None   345600.0     None       1      10   \n",
      "3    2023-04-07 23:56:39-06:00    None    36000.0     None      16    2048   \n",
      "4    2023-04-07 23:56:00-06:00    None   345600.0     None       1     128   \n",
      "6    2023-04-07 23:55:39-06:00    None    10800.0     None       1       2   \n",
      "...                        ...     ...        ...      ...     ...     ...   \n",
      "6067 2023-04-07 01:03:54-06:00    None     5400.0     None       1       5   \n",
      "6068 2023-04-07 01:00:26-06:00    None    86400.0     None       2     256   \n",
      "6071 2023-04-07 00:49:27-06:00    None     1800.0     None       1     127   \n",
      "6072 2023-04-07 00:25:17-06:00    None    14400.0     None       1       4   \n",
      "6073 2023-04-07 00:24:52-06:00    None    14400.0     None       1       4   \n",
      "\n",
      "      ngpus  username   account      queue state        jobname   exitcode  \\\n",
      "1         0  USER1495   GROUP33     shared  None      JOBNAME80  CANCELLED   \n",
      "2         0  USER1936  GROUP206     shared  None  JOBNAME217720  COMPLETED   \n",
      "3         0  USER1885  GROUP198       wide  None     JOBNAME822    TIMEOUT   \n",
      "4         0    USER21   GROUP81   standard  None  JOBNAME261231  COMPLETED   \n",
      "6         0  USER1279   GROUP33     shared  None      JOBNAME80    TIMEOUT   \n",
      "...     ...       ...       ...        ...   ...            ...        ...   \n",
      "6067      0  USER1375   GROUP33     shared  None      JOBNAME80  COMPLETED   \n",
      "6068      0    USER65   GROUP40  wholenode  None  JOBNAME217727     FAILED   \n",
      "6071      0  USER1545  GROUP125     shared  None      JOBNAME47  COMPLETED   \n",
      "6072      0  USER1936  GROUP206     shared  None  JOBNAME148708  COMPLETED   \n",
      "6073      0  USER1936  GROUP206     shared  None  JOBNAME148794  COMPLETED   \n",
      "\n",
      "                                              host_list  \n",
      "1                                             [NODE406]  \n",
      "2                                             [NODE918]  \n",
      "3     [NODE68, NODE69, NODE160, NODE131, NODE33, NOD...  \n",
      "4                                             [NODE224]  \n",
      "6                                             [NODE406]  \n",
      "...                                                 ...  \n",
      "6067                                          [NODE887]  \n",
      "6068                                   [NODE92, NODE94]  \n",
      "6071                                          [NODE925]  \n",
      "6072                                          [NODE912]  \n",
      "6073                                          [NODE912]  \n",
      "\n",
      "[1189 rows x 17 columns]\n",
      "Do you want to download the filtered timeseries data?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Button(description='Download as CSV', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df84ba6f4c5c42428cddde56a26ba437"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Button(description='Download as Excel', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9981c26ae294f69b9d4401786bbc37b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to download the filtered accounting data?\n"
     ]
    },
    {
     "data": {
      "text/plain": "Button(description='Download as CSV', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7815dba86be4738816b6cfef238ff04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Button(description='Download as Excel', style=ButtonStyle())",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c222ba1ac85946e3b549aac910781295"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select a statistic to calculate.\n"
     ]
    },
    {
     "data": {
      "text/plain": "SelectMultiple(description='Statistics', index=(0,), options=('None', 'Average', 'Median', 'Standard Deviation…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c07004beb31d4d35a009bf00ae570198"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the threshold if 'Ratio of Data Outside Threshold' was selected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "IntText(value=0, description='Value:', disabled=True)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d10ecd0d9c940fabc8a4cfc4a7e41f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select an interval type to use in the statistic calculation. If count is selected, the interval will correspond to a count of rows. If time is selected, the interval will be a time window.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dropdown(description='Interval Type', disabled=True, options=('None', 'Count', 'Time'), value='None')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e4b8afb3f614b2c9909dde830cf312e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If time was selected, please select the unit of time.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dropdown(description='Interval Unit', disabled=True, options=('None', 'Days', 'Hours', 'Minutes', 'Seconds'), …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f43f60d84c624ac296fa40f2f52b0ce6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the interval count.\n"
     ]
    },
    {
     "data": {
      "text/plain": "IntText(value=0, description='Value:', disabled=True)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fbac93746874cdca9b69b991ca5529a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------- CELL 4 --------------\n",
    "ts_copy = time_series_df.copy()\n",
    "acc_copy = account_log_df.copy()\n",
    "\n",
    "if units.value != \"None\":\n",
    "    ts_copy = nbf.get_timeseries_by_values_and_unit(unit_values, ts_copy)\n",
    "\n",
    "if len(hosts.value) > 0:\n",
    "    ts_copy = nbf.get_timeseries_by_hosts(hosts.value, ts_copy)\n",
    "\n",
    "if len(job_ids.value) > 0:\n",
    "    account_log_df = nbf.get_timeseries_by_job_ids(job_ids.value, ts_copy)\n",
    "\n",
    "if return_account_logs:\n",
    "    account_log_df = nbf.get_account_logs_by_job_ids(ts_copy, account_log_df)\n",
    "\n",
    "if any(selection != \"None\" for selection in timeseries_return_columns.value):\n",
    "    col_map = {'Job Id': 'jid', 'Hosts': 'host', 'Events': 'event', 'Units': 'unit', 'Values': 'value', 'Timestamps': 'time'}\n",
    "    ts_copy = nbf.filter_return_columns([col_map[selection] for selection in timeseries_return_columns.value if selection != \"None\"], ts_copy)\n",
    "\n",
    "# -------------- timeseries download --------------\n",
    "print(\"Do you want to download the filtered timeseries data?\")\n",
    "csv_download_button = widgets.Button(description=\"Download as CSV\")\n",
    "excel_download_button = widgets.Button(description=\"Download as Excel\")\n",
    "def on_csv_button_clicked(b):\n",
    "    display(nbf.create_csv_download_link(time_series_df, title=\"Download timeseries CSV\"))\n",
    "\n",
    "def on_excel_button_clicked(b):\n",
    "    display(nbf.create_excel_download_link(time_series_df, title=\"Download timeseries Excel\"))\n",
    "\n",
    "csv_download_button.on_click(on_csv_button_clicked)\n",
    "excel_download_button.on_click(on_excel_button_clicked)\n",
    "display(csv_download_button, excel_download_button)\n",
    "\n",
    "# -------------- account log download --------------\n",
    "\n",
    "print(\"Do you want to download the filtered accounting data?\")\n",
    "csv_acc_download_button = widgets.Button(description=\"Download as CSV\")\n",
    "excel_acc_download_button = widgets.Button(description=\"Download as Excel\")\n",
    "\n",
    "def on_acc_csv_button_clicked(b):\n",
    "    display(nbf.create_csv_download_link(account_log_df, title=\"Download accounting CSV\"))\n",
    "\n",
    "def on_acc_excel_button_clicked(b):\n",
    "    display(nbf.create_excel_download_link(account_log_df, title=\"Download accounting Excel\"))\n",
    "\n",
    "csv_acc_download_button.on_click(on_acc_csv_button_clicked)\n",
    "excel_acc_download_button.on_click(on_acc_excel_button_clicked)\n",
    "display(csv_acc_download_button, excel_acc_download_button)\n",
    "\n",
    "# -------------- stats options --------------\n",
    "stats = widgets.SelectMultiple(\n",
    "    options=['None', 'Average', 'Median', 'Standard Deviation', 'PDF', 'CDF', 'Ratio of Data Outside Threshold'],\n",
    "    value=['None'],\n",
    "    description='Statistics',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "ratio_threshold = widgets.IntText(\n",
    "    value=0,\n",
    "    description='Value:',\n",
    "    disabled=True  # disabled by default\n",
    ")\n",
    "\n",
    "interval_type = widgets.Dropdown(\n",
    "    options=['None', 'Count', 'Time'],\n",
    "    value='None',\n",
    "    description='Interval Type',\n",
    "    disabled=True  # disabled by default\n",
    ")\n",
    "\n",
    "time_units = widgets.Dropdown(\n",
    "    options=['None', 'Days', 'Hours', 'Minutes', 'Seconds'],\n",
    "    value='None',\n",
    "    description='Interval Unit',\n",
    "    disabled=True  # disabled by default\n",
    ")\n",
    "\n",
    "time_value = widgets.IntText(\n",
    "    value=0,\n",
    "    description='Value:',\n",
    "    disabled=True  # disabled by default\n",
    ")\n",
    "\n",
    "# Define a function to be called when stats value changes\n",
    "def on_stats_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        if \"Ratio of Data Outside Threshold\" in change['new']: \n",
    "            # enable ratio_threshold if 'Ratio of Data Outside Threshold' is selected\n",
    "            ratio_threshold.disabled = False\n",
    "        else: \n",
    "            # disable ratio_threshold if 'Ratio of Data Outside Threshold' is not selected\n",
    "            ratio_threshold.disabled = True\n",
    "\n",
    "        if change['new'][0] != \"None\":  \n",
    "            # enable interval_type if stats is not None\n",
    "            interval_type.disabled = False\n",
    "        else:  \n",
    "            # disable interval_type if stats is None\n",
    "            interval_type.disabled = True\n",
    "            interval_type.value = 'None'  # reset interval_type to 'None'\n",
    "\n",
    "stats.observe(on_stats_change)\n",
    "\n",
    "# Define a function to be called when interval_type value changes\n",
    "def on_interval_type_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        if change['new'] == \"None\":\n",
    "            time_units.disabled = True\n",
    "            time_value.disabled = True\n",
    "            time_units.value = 'None'  # reset time_units to 'None'\n",
    "            time_value.value = 0  # reset time_value to 0\n",
    "        elif change['new'] == \"Time\":\n",
    "            time_units.disabled = False\n",
    "            time_value.disabled = False\n",
    "        elif change['new'] == \"Count\":\n",
    "            time_units.disabled = True\n",
    "            time_value.disabled = False\n",
    "        else:\n",
    "            time_units.disabled = False\n",
    "            time_value.disabled = False\n",
    "\n",
    "interval_type.observe(on_interval_type_change)\n",
    "\n",
    "# Display the widgets\n",
    "print(\"Please select a statistic to calculate.\")\n",
    "display(stats)\n",
    "print(\"Please provide the threshold if 'Ratio of Data Outside Threshold' was selected.\")\n",
    "display(ratio_threshold)\n",
    "print(\"Please select an interval type to use in the statistic calculation. If count is selected, the interval will correspond to a count of rows. If time is selected, the interval will be a time window.\")\n",
    "display(interval_type)\n",
    "print(\"If time was selected, please select the unit of time.\")\n",
    "display(time_units)\n",
    "print(\"Please provide the interval count.\")\n",
    "display(time_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7bfc5a6-2e81-4ad1-b1e9-b4053f317d70",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-07-29T17:43:24.868106900Z",
     "start_time": "2023-07-29T17:43:20.984043300Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Job Id', 'Host', 'Event', 'Units'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 73\u001B[0m\n\u001B[0;32m     71\u001B[0m     rolling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m interval_type\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCount\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 73\u001B[0m     unit_stat_dfs[unit][metric] \u001B[38;5;241m=\u001B[39m \u001B[43mmetric_func_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmetric_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     rolling \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\fresco-updates\\notebook_functions.py:440\u001B[0m, in \u001B[0;36mget_average\u001B[1;34m(time_series, rolling, window)\u001B[0m\n\u001B[0;32m    421\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;124;03mCalculates the median of the provided time_series DataFrame, either on the entire DataFrame or on a rolling window\u001B[39;00m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;124;03mbasis.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;124;03m         rolling is False, the result will be a Series with the overall median.\u001B[39;00m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    439\u001B[0m result \u001B[38;5;241m=\u001B[39m time_series\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m--> 440\u001B[0m \u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mJob Id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mHost\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mEvent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUnits\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rolling:\n\u001B[0;32m    443\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39mrolling(window\u001B[38;5;241m=\u001B[39mwindow)\u001B[38;5;241m.\u001B[39mmean()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:5258\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   5110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[0;32m   5111\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   5112\u001B[0m     labels: IndexLabel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5119\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   5120\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5121\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5122\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[0;32m   5123\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5256\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[0;32m   5257\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 5258\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5259\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5260\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5264\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5265\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5266\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:4549\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   4547\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m   4548\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 4549\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[0;32m   4552\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:4591\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[1;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[0;32m   4589\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   4590\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 4591\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4592\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[0;32m   4594\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[0;32m   4595\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6696\u001B[0m, in \u001B[0;36mIndex.drop\u001B[1;34m(self, labels, errors)\u001B[0m\n\u001B[0;32m   6694\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m   6695\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 6696\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(labels[mask])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6697\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[0;32m   6698\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['Job Id', 'Host', 'Event', 'Units'] not found in axis\""
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# -------------- CELL 5 --------------\n",
    "# Convert the 'Timestamp' columns to datetime\n",
    "try:\n",
    "    time_series_df['time'] = pd.to_datetime(time_series_df['time'])\n",
    "    # account_log_df['time'] = pd.to_datetime(account_log_df['time'])\n",
    "\n",
    "    # set the 'Timestamp' column as the index\n",
    "    time_series_df = time_series_df.set_index('time')\n",
    "    # account_log_df = account_log_df.set_index('Timestamp')\n",
    "\n",
    "    # sort each by timestamp\n",
    "    time_series_df = time_series_df.sort_index()\n",
    "    # account_log_df = account_log_df.sort_index()\n",
    "except Exception as e:\n",
    "    print(\"Encountered the following error: {e}\")\n",
    "\n",
    "df_avg, df_mean, df_median, df_std = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "pdf, cdf, ratio, rolling = False, False, False, False\n",
    "\n",
    "metric_func_map = {\n",
    "    \"Average\": nbf.get_average,\n",
    "    \"Median\": nbf.get_median,\n",
    "    \"Standard Deviation\": nbf.get_standard_deviation,\n",
    "    \"PDF\": nbf.plot_pdf,\n",
    "    \"CDF\": nbf.plot_cdf,\n",
    "    \"Ratio of Data Outside Threshold\": nbf.plot_data_points_outside_threshold\n",
    "}\n",
    "\n",
    "unit_map = {\n",
    "    \"CPU %\": \"cpuuser\",\n",
    "    \"GPU %\": \"gpu_usage\",\n",
    "    \"GB:memused\": \"memused\",\n",
    "    \"GB:memused_minus_diskcache\": \"memused_minus_diskcache\",\n",
    "    \"GB/s\": \"block\",\n",
    "    \"MB/s\": \"nfs\"\n",
    "}\n",
    "\n",
    "# set up outputs and tabbed layout\n",
    "tab = widgets.Tab()\n",
    "outputs = {}\n",
    "for unit in units.value:\n",
    "    outputs[unit] = {}\n",
    "    for stat in stats.value:\n",
    "        outputs[unit][stat] = widgets.Output()\n",
    "tab.children = [widgets.Accordion([widgets.Box([widgets.Label(stat), outputs[unit][stat]]) for stat in stats.value], titles=stats.value) for unit in units.value]\n",
    "tab.titles = units.value\n",
    "\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    unit_stat_dfs = {}\n",
    "    time_map = {'Days': 'D', 'Hours': 'H', 'Minutes': 'T', 'Seconds': 'S'}\n",
    "    for unit in units.value:\n",
    "        unit_stat_dfs[unit] = {}\n",
    "        for metric in stats.value:\n",
    "            metric_df = time_series_df.query(f\"`event` == '{unit_map[unit]}'\")\n",
    "            # handle special cases\n",
    "            if metric == \"PDF\" or metric == \"CDF\":\n",
    "                with outputs[unit][metric]:\n",
    "                    metric_func_map[metric](metric_df)\n",
    "                continue\n",
    "            elif metric == \"Ratio of Data Outside Threshold\":\n",
    "                with outputs[unit][metric]:\n",
    "                    metric_func_map[metric](ratio_threshold.value, metric_df)\n",
    "                continue\n",
    "            \n",
    "            # calculate stats\n",
    "            if interval_type.value == \"Time\":\n",
    "                unit_stat_dfs[unit][metric] = metric_func_map[metric](metric_df, True, f\"{time_value.value}{time_map[time_units.value]}\")\n",
    "                rolling = True\n",
    "            elif interval_type.value == \"Count\":\n",
    "                unit_stat_dfs[unit][metric] = metric_func_map[metric](metric_df, True, time_value.value)\n",
    "                rolling = True\n",
    "            else:\n",
    "                unit_stat_dfs[unit][metric] = metric_func_map[metric](metric_df, False)\n",
    "            \n",
    "            # plot stats\n",
    "            if rolling:\n",
    "                with outputs[unit][metric]:\n",
    "                    unit_stat_dfs[unit][metric].plot()\n",
    "                    x_axis_label = \"\"\n",
    "                    if interval_type.value == \"Count\":\n",
    "                        x_axis_label += f\"Timestamp - Rolling Window: {time_value:,} Rows\"\n",
    "                    elif interval_type.value == \"Time\":\n",
    "                        x_axis_label += f\"Timestamp - Rolling Window: {time_value.value}{time_map[time_units.value]}\"\n",
    "                    y_axis_label = unit\n",
    "                    plt.gcf().autofmt_xdate()  # auto formats datetimes\n",
    "                    plt.style.use('fivethirtyeight')\n",
    "                    plt.title(f\"{unit} {metric}\")\n",
    "                    plt.legend(loc='upper left', fontsize=\"10\")\n",
    "                    plt.xlabel(x_axis_label)\n",
    "                    plt.ylabel(y_axis_label)\n",
    "                    plt.show()\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a87e2db6-e306-4811-8dc6-c550936f20a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select two metrics below to find their Pearson correlation:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eeaa3c83b24a309f2d566c49d20b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(SelectMultiple(description='Metrics', index=(0,), options=('None', 'cpuuser', 'g…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------- CELL 6 --------------\n",
    "def on_selection_change(change):\n",
    "    if len(change.new) > 2:\n",
    "        correlations.value = change.new[:2]\n",
    "        \n",
    "def on_button_click(button):\n",
    "    graph_output.clear_output()\n",
    "    with graph_output:\n",
    "        with plt.style.context('fivethirtyeight'):\n",
    "            display(nbf.calculate_and_plot_correlation(time_series_df, correlations.value))\n",
    "\n",
    "correlations = widgets.SelectMultiple(\n",
    "    options=['None', 'cpuuser', 'gpu_usage', 'nfs', 'block', 'memused', 'memused_minus_diskcache'],\n",
    "    value=['None'],\n",
    "    description='Metrics',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "plot_button = widgets.Button(\n",
    "    description = \"Plot correlation\",\n",
    "    disabled = False,\n",
    "    icon= \"chart-line\"\n",
    ")\n",
    "plot_button.on_click(on_button_click)\n",
    "\n",
    "graph_output = widgets.Output()\n",
    "\n",
    "container = widgets.VBox(\n",
    "    [widgets.HBox([correlations, plot_button], layout = widgets.Layout(\n",
    "        width = \"50%\", \n",
    "        justify_content=\"space-between\", \n",
    "        align_items=\"center\"),),\n",
    "    graph_output])\n",
    "correlations.observe(on_selection_change, names='value')\n",
    "\n",
    "# Give the user the option to calculate correlations\n",
    "print(\"Please select two metrics below to find their Pearson correlation:\")\n",
    "display(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- CELL 7 ---------------\n",
    "\n",
    "# Give the user the option to download data here.\n",
    "print(\"Select the files to be downloaded:\")\n",
    "files_to_provide = widgets.SelectMultiple(\n",
    "    options=['None', 'job_ts_metrics_aug2022_anon', 'job_ts_metrics_dec2022_anon',\n",
    "             'job_ts_metrics_jan2022_anon', 'job_ts_metrics_july2022_anon',\n",
    "             'job_ts_metrics_nov2022_anon', 'job_ts_metrics_sep2022_anon'],\n",
    "    value=['None'],\n",
    "    description='Files',\n",
    "    disabled=False\n",
    ")\n",
    "display(files_to_provide)\n",
    "\n",
    "# Create and display download button\n",
    "download_button = widgets.Button(description='Download File/s')\n",
    "download_button.on_click(nbf.on_download_button_clicked)\n",
    "display(download_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e516ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- CELL 9 ---------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
