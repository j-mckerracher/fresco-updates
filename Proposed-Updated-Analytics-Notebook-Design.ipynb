{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25999cae",
   "metadata": {},
   "source": [
    "# FRESCO Analytics Notebook\n",
    "### Overview\n",
    "This notebook has been designed to make analysis of the Anvil dataset as easy as possible. Generally speaking, it will allow the user to access the Anvil files stored locally, select a number of analysis options, and view the results.\n",
    "\n",
    "The notebook can be divided into three sections:\n",
    "#### Section 1: Data Filtering\n",
    "This initial section is your gateway to defining the precise scope of your analysis. Select a specific datetime window and apply various filters to customize your dataset to your needs.\n",
    "\n",
    "#### Section 2: Data Analysis Options\n",
    "The second section provides a suite of analysis options. Here, you have the liberty to pick and choose the analysis that fits your needs.\n",
    "\n",
    "#### Section 3: Data Analysis and Visualizations\n",
    "The final section of this notebook performs the selected analysis option on the filtered dataset, and provides visualizations of those analyses.\n",
    "\n",
    "### Step-by-Step Instructions\n",
    "1. **Cell 1:** Start by defining the temporal boundaries of your dataset. This time frame will dictate the extraction of relevant host time series and job accounting data from the database.\n",
    "2. **Cell 2:** Here, choose your preferred preprocessing methods. Multiple methods can be combined.\n",
    "3. **Cell 3:** Specify the units for the time series data of the host that you wish to be included in the analysis.\n",
    "4. **Cell 4:** Here, you input your desired values and select options. **Remember:** If units were selected in step 3, ensure the low and high values are added here, and click the **\"Save Values\"** button before moving forward.\n",
    "5. **Cell 5:** This step involves two actions:\n",
    "- Download Option: You can choose to download the filtered dataset for offline use or further analysis.\n",
    "- Analysis Selection: Choose from various data analysis options for your filtered dataset.\n",
    "6. **Cell 6:** Running this cell will generate all the data visualizations. If you would like to explore correlations among metrics and statistics, select from the provided options.\n",
    "7. **Cell 7:** Run to see correlations.\n",
    "8. **Cell 8:** TBD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c04de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T20:21:43.968072200Z",
     "start_time": "2023-07-08T20:21:43.233758700Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------- CELL 1 --------------\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import notebook_functions as nbf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(r\"Please provide a time window for your dataset.\")\n",
    "\n",
    "start_time = widgets.NaiveDatetimePicker(\n",
    "    value=datetime.now().replace(microsecond=0),\n",
    "    placeholder='',\n",
    "    description='Start Time:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "end_time = widgets.NaiveDatetimePicker(\n",
    "    value=datetime.now().replace(microsecond=0),\n",
    "    placeholder='',\n",
    "    description='End Time:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def validate_date_range(change):\n",
    "    # 'change' includes information about the change event\n",
    "    # including the 'owner' which is the widget itself\n",
    "    if change['owner'] == start_time:\n",
    "        if end_time.value and change['new'] >= end_time.value:\n",
    "            print(\"Error: Start Time should be less than End Time\")\n",
    "        else:\n",
    "            print(\"Time range is valid\")\n",
    "    elif change['owner'] == end_time:\n",
    "        if start_time.value and change['new'] <= start_time.value:\n",
    "            print(\"Error: End Time should be greater than Start Time\")\n",
    "        else:\n",
    "            print(\"Time range is valid\")\n",
    "\n",
    "# Attach the validation function to the 'value' trait of the date picker widgets\n",
    "start_time.observe(validate_date_range, 'value')\n",
    "end_time.observe(validate_date_range, 'value')\n",
    "\n",
    "display(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff024e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T20:22:09.535849600Z",
     "start_time": "2023-07-08T20:22:09.526688Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------- CELL 2 --------------\n",
    "\n",
    "print(\"Data preprocessing: select one or many:\")\n",
    "preprocessing = widgets.SelectMultiple(\n",
    "    options=['None', 'Remove Rows with Missing Metric', 'Remove Rows with Negative Value', 'Add an Interval Column'],\n",
    "    value=['None'],\n",
    "    description='Options:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bb83db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T20:22:13.823538200Z",
     "start_time": "2023-07-08T20:22:11.522793Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------- CELL 3 --------------\n",
    "\n",
    "# get timeseries from the DB\n",
    "# time_series_df = nbf.get_time_series_from_database(start_time.value.strftime('%Y-%m-%d %H:%M:%S'), end_time.value.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# TODO: REMOVE WHEN DONE WITH DEV\n",
    "time_series_df = pd.read_csv(\"job_ts_metrics_july2022_anon.csv\")\n",
    "# TODO: REMOVE WHEN DONE WITH DEV\n",
    "\n",
    "# get the account logs from the DB\n",
    "account_log_df = nbf.get_account_log_from_database(start_time.value.strftime('%Y-%m-%d %H:%M:%S'), end_time.value.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# do the preprocessing\n",
    "for value in preprocessing.value:\n",
    "    if \"Missing Metric\" in value:\n",
    "        time_series_df = time_series_df.dropna()\n",
    "    if \"Add\" in value:\n",
    "        time_series_df = nbf.add_interval_column(end_time.value, time_series_df)\n",
    "    if \"Negative Value\":\n",
    "        time_series_df = time_series_df[time_series_df['Value'] >= 0]\n",
    "\n",
    "print(\"Optional: select the units to be included in the timeseries data.\")\n",
    "units = widgets.SelectMultiple(\n",
    "    options=['None', 'CPU %', 'GPU %', 'GB:memused', 'GB:memused_minus_diskcache', 'GB/s', 'MB/s'],\n",
    "    value=['None'],\n",
    "    description='Units:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb487b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T20:22:19.444507500Z",
     "start_time": "2023-07-08T20:22:19.426882900Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------- CELL 4 --------------\n",
    "\n",
    "unit_values = {}  # stores user low and high value user input such that: key = a unit from the units list above /// value = (low_value, high_value)\n",
    "\n",
    "for value in units.value:\n",
    "    if value != 'None':\n",
    "        nbf.setup_widgets(unit_values, value)\n",
    "\n",
    "print(\"Optional: provide the hosts to be included in the timeseries data e.g., 'NODE1, NODE2'\")\n",
    "hosts = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='Hosts:',\n",
    "    disabled=False\n",
    ")\n",
    "display(hosts)\n",
    "\n",
    "print(\"Optional: provide the jobs to be included in the timeseries data e.g., 'JOB1, JOB2'\")\n",
    "job_ids = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='',\n",
    "    description='Jobs:',\n",
    "    disabled=False\n",
    ")\n",
    "display(job_ids)\n",
    "\n",
    "print(\"Optional: select if you want the account logs to be returned for the Job IDs matching your query.\")\n",
    "return_account_logs = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Account Logs',\n",
    "    disabled=False,\n",
    "    button_style='',\n",
    "    tooltip='Return Account Logs?',\n",
    "    icon='check'\n",
    ")\n",
    "display(return_account_logs)\n",
    "\n",
    "print(\"Optional: select the columns to be included in the timeseries data (hold control to select multiple). If no columns are \"\n",
    "      \"selected, all columns will be included.\")\n",
    "timeseries_return_columns = widgets.SelectMultiple(\n",
    "    options=['None', 'Job Id', 'Hosts', 'Events', 'Units', 'Values', 'Timestamps'],\n",
    "    value=['None'],\n",
    "    description='Return Columns',\n",
    "    disabled=False\n",
    ")\n",
    "display(timeseries_return_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b1281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T20:22:26.907172600Z",
     "start_time": "2023-07-08T20:22:26.826099700Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------- CELL 5 --------------\n",
    "\n",
    "# if units.value != \"None\":\n",
    "#     time_series_df = nbf.get_timeseries_by_values_and_unit(unit_values, time_series_df)\n",
    "#\n",
    "# if len(hosts.value) > 0:\n",
    "#     time_series_df = nbf.get_timeseries_by_hosts(hosts.value, time_series_df)\n",
    "#\n",
    "# if len(job_ids.value) > 0:\n",
    "#     account_log_df = nbf.get_timeseries_by_job_ids(job_ids.value)\n",
    "#\n",
    "# if return_account_logs:\n",
    "#     account_log_df = nbf.get_account_logs_by_job_ids(time_series_df, account_log_df)\n",
    "\n",
    "# -------------- timeseries download --------------\n",
    "\n",
    "print(\"Do you want to download the filtered timeseries data?\")\n",
    "csv_download_button = widgets.Button(description=\"Download as CSV\")\n",
    "excel_download_button = widgets.Button(description=\"Download as Excel\")\n",
    "def on_csv_button_clicked(b):\n",
    "    display(nbf.create_csv_download_link(time_series_df, title=\"Download timeseries CSV\"))\n",
    "\n",
    "def on_excel_button_clicked(b):\n",
    "    display(nbf.create_excel_download_link(time_series_df, title=\"Download timeseries Excel\"))\n",
    "\n",
    "csv_download_button.on_click(on_csv_button_clicked)\n",
    "excel_download_button.on_click(on_excel_button_clicked)\n",
    "display(csv_download_button, excel_download_button)\n",
    "\n",
    "# -------------- account log download --------------\n",
    "\n",
    "print(\"Do you want to download the filtered accounting data?\")\n",
    "csv_acc_download_button = widgets.Button(description=\"Download as CSV\")\n",
    "excel_acc_download_button = widgets.Button(description=\"Download as Excel\")\n",
    "\n",
    "def on_acc_csv_button_clicked(b):\n",
    "    display(nbf.create_csv_download_link(account_log_df, title=\"Download accounting CSV\"))\n",
    "\n",
    "def on_acc_excel_button_clicked(b):\n",
    "    display(nbf.create_excel_download_link(account_log_df, title=\"Download accounting Excel\"))\n",
    "\n",
    "csv_acc_download_button.on_click(on_acc_csv_button_clicked)\n",
    "excel_acc_download_button.on_click(on_acc_excel_button_clicked)\n",
    "display(csv_acc_download_button, excel_acc_download_button)\n",
    "\n",
    "# -------------- stats options --------------\n",
    "stats = widgets.SelectMultiple(\n",
    "    options=['None', 'Average', 'Mean', 'Median', 'Standard Deviation', 'PDF', 'CDF', 'Ratio of Data Outside Threshold'],\n",
    "    value=['None'],\n",
    "    description='Statistics',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "ratio_threshold = widgets.IntText(\n",
    "    value=0,\n",
    "    description='Value:',\n",
    "    disabled=True  # disabled by default\n",
    ")\n",
    "\n",
    "interval_type = widgets.Dropdown(\n",
    "    options=['None', 'Count', 'Time'],\n",
    "    value='None',\n",
    "    description='Interval Type',\n",
    "    disabled=True  # disabled by default\n",
    ")\n",
    "\n",
    "time_units = widgets.Dropdown(\n",
    "    options=['None', 'Days', 'Hours', 'Minutes', 'Seconds'],\n",
    "    value='None',\n",
    "    description='Interval Unit',\n",
    "    disabled=True  # disabled by default\n",
    ")\n",
    "\n",
    "time_value = widgets.IntText(\n",
    "    value=0,\n",
    "    description='Value:',\n",
    "    disabled=True  # disabled by default\n",
    ")\n",
    "\n",
    "# Define a function to be called when stats value changes\n",
    "def on_stats_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        if \"Ratio of Data Outside Threshold\" in change['new']: \n",
    "            # enable ratio_threshold if 'Ratio of Data Outside Threshold' is selected\n",
    "            ratio_threshold.disabled = False\n",
    "        else: \n",
    "            # disable ratio_threshold if 'Ratio of Data Outside Threshold' is not selected\n",
    "            ratio_threshold.disabled = True\n",
    "\n",
    "        if change['new'][0] != \"None\":  \n",
    "            # enable interval_type if stats is not None\n",
    "            interval_type.disabled = False\n",
    "        else:  \n",
    "            # disable interval_type if stats is None\n",
    "            interval_type.disabled = True\n",
    "            interval_type.value = 'None'  # reset interval_type to 'None'\n",
    "\n",
    "stats.observe(on_stats_change)\n",
    "\n",
    "# Define a function to be called when interval_type value changes\n",
    "def on_interval_type_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        if change['new'] == \"None\":\n",
    "            time_units.disabled = True\n",
    "            time_value.disabled = True\n",
    "            time_units.value = 'None'  # reset time_units to 'None'\n",
    "            time_value.value = 0  # reset time_value to 0\n",
    "        elif change['new'] == \"Time\":\n",
    "            time_units.disabled = False\n",
    "            time_value.disabled = False\n",
    "        elif change['new'] == \"Count\":\n",
    "            time_units.disabled = True\n",
    "            time_value.disabled = False\n",
    "        else:\n",
    "            time_units.disabled = False\n",
    "            time_value.disabled = False\n",
    "\n",
    "interval_type.observe(on_interval_type_change)\n",
    "\n",
    "# Display the widgets\n",
    "print(\"Please select a statistic to calculate.\")\n",
    "display(stats)\n",
    "print(\"Please provide the threshold if 'Ratio of Data Outside Threshold' was selected.\")\n",
    "display(ratio_threshold)\n",
    "print(\"Please select an interval type to use in the statistic calculation. If count is selected, the interval will correspond to a count of rows. If time is selected, the interval will be a time window.\")\n",
    "display(interval_type)\n",
    "print(\"If time was selected, please select the unit of time.\")\n",
    "display(time_units)\n",
    "print(\"Please provide the interval count.\")\n",
    "display(time_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e03c05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T20:22:53.712663600Z",
     "start_time": "2023-07-08T20:22:44.458068400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -------------- CELL 6 --------------\n",
    "# Convert the 'Timestamp' columns to datetime\n",
    "time_series_df['Timestamp'] = pd.to_datetime(time_series_df['Timestamp'])\n",
    "# account_log_df['Timestamp'] = pd.to_datetime(account_log_df['Timestamp'])\n",
    "\n",
    "# set the 'Timestamp' column as the index\n",
    "time_series_df = time_series_df.set_index('Timestamp')\n",
    "# account_log_df = account_log_df.set_index('Timestamp')\n",
    "\n",
    "# sort each by timestamp\n",
    "time_series_df = time_series_df.sort_index()\n",
    "# account_log_df = account_log_df.sort_index()\n",
    "\n",
    "df_avg, df_mean, df_median, df_std = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "pdf, cdf, ratio, rolling = False, False, False, False\n",
    "\n",
    "# Calculate stats:\n",
    "time_map = {'Days': 'D', 'Hours': 'H', 'Minutes': 'T', 'Seconds': 'S'}\n",
    "\n",
    "for choice in stats.value:\n",
    "    if choice == \"Average\":\n",
    "        if interval_type.value == \"Time\":\n",
    "            df_avg = nbf.get_average(time_series_df, True, f\"{time_value.value}{time_map[time_units.value]}\")\n",
    "            rolling = True\n",
    "        elif interval_type.value == \"Count\":\n",
    "            df_avg = nbf.get_average(time_series_df, True, time_value.value)\n",
    "            rolling = True\n",
    "        else:\n",
    "            df_avg = nbf.get_average(time_series_df)\n",
    "    if choice == \"Mean\":\n",
    "        if interval_type.value == \"Time\":\n",
    "            df_mean = nbf.get_mean(time_series_df, True, f\"{time_value.value}{time_map[time_units.value]}\")\n",
    "            rolling = True\n",
    "        elif interval_type.value == \"Count\":\n",
    "            df_mean = nbf.get_mean(time_series_df, True, time_value.value)\n",
    "            rolling = True\n",
    "        else:\n",
    "            df_mean = nbf.get_mean(time_series_df)\n",
    "    if choice == \"Median\":\n",
    "        if interval_type.value == \"Time\":\n",
    "            df_median = nbf.get_median(time_series_df, True, f\"{time_value.value}{time_map[time_units.value]}\")\n",
    "            rolling = True\n",
    "        elif interval_type.value == \"Count\":\n",
    "            df_median = nbf.get_median(time_series_df, True, time_value.value)\n",
    "            rolling = True\n",
    "        else:\n",
    "            df_median = nbf.get_median(time_series_df)\n",
    "    if choice == \"Standard Deviation\":\n",
    "        if interval_type.value == \"Time\":\n",
    "            df_std = nbf.get_standard_deviation(time_series_df, True,\n",
    "                                                f\"{time_value.value}{time_map[time_units.value]}\")\n",
    "            rolling = True\n",
    "        elif interval_type.value == \"Count\":\n",
    "            df_std = nbf.get_standard_deviation(time_series_df, True, time_value.value)\n",
    "            rolling = True\n",
    "        else:\n",
    "            df_std = nbf.get_standard_deviation(time_series_df)\n",
    "    if choice == \"PDF\":\n",
    "        pdf = True\n",
    "    if choice == \"CDF\":\n",
    "        cdf = True\n",
    "    if choice == \"Ratio of Data Outside Threshold\":\n",
    "        ratio = True\n",
    "\n",
    "# Get choices and plot\n",
    "nbf.plot_choices(stats.value, rolling, df_avg, df_mean, df_median, df_std, start_time.value, end_time.value)\n",
    "\n",
    "# ********************** basic stats plot formatting & show **********************\n",
    "if rolling:\n",
    "    nbf.plot_rolling_basic_stats(interval_type.value, time_value.value, time_units.value, unit_values)\n",
    "\n",
    "# ********************** box and whisker plot **********************\n",
    "if rolling:\n",
    "    nbf.plot_box_and_whisker(df_avg, df_mean, df_std, df_median)\n",
    "\n",
    "# ********************** PDF plot formatting & show **********************\n",
    "if pdf:\n",
    "    nbf.plot_pdf(time_series_df.copy())\n",
    "\n",
    "# ********************** CDF plot formatting & show **********************\n",
    "if cdf:\n",
    "    nbf.plot_cdf(time_series_df.copy())\n",
    "    \n",
    "# ********************** Ratio of Data Outside Threshold plot **********************\n",
    "if ratio:\n",
    "    nbf.plot_data_points_outside_threshold(ratio_threshold.value, time_series_df.copy())\n",
    "\n",
    "# Give the user the option to calculate correlations\n",
    "print(\"Please select two metrics below to find their Pearson correlation:\")\n",
    "\n",
    "def on_selection_change(change):\n",
    "    if len(change.new) > 2:\n",
    "        correlations.value = change.new[:2]\n",
    "\n",
    "correlations = widgets.SelectMultiple(\n",
    "    options=['None', 'cpuuser', 'gpu_usage', 'nfs', 'block', 'memused', 'memused_minus_diskcache'],\n",
    "    value=['None'],\n",
    "    description='Metrics',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "correlations.observe(on_selection_change, names='value')\n",
    "display(correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614ebea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-08T20:23:22.209528500Z",
     "start_time": "2023-07-08T20:23:21.373971200Z"
    }
   },
   "outputs": [],
   "source": [
    "# -------------- CELL 7 --------------\n",
    "\n",
    "# calculate correlations\n",
    "nbf.calculate_and_plot_correlation(time_series_df.copy(), correlations.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e150e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- CELL 8 ---------------\n",
    "\n",
    "# Give the user the option to download data here.\n",
    "print(\"Select the files to be downloaded:\")\n",
    "files_to_provide = widgets.SelectMultiple(\n",
    "    options=['None', 'job_ts_metrics_aug2022_anon', 'job_ts_metrics_dec2022_anon',\n",
    "             'job_ts_metrics_jan2022_anon', 'job_ts_metrics_july2022_anon',\n",
    "             'job_ts_metrics_nov2022_anon', 'job_ts_metrics_sep2022_anon'],\n",
    "    value=['None'],\n",
    "    description='Files',\n",
    "    disabled=False\n",
    ")\n",
    "display(files_to_provide)\n",
    "\n",
    "# Create and display download button\n",
    "download_button = widgets.Button(description='Download File/s')\n",
    "download_button.on_click(nbf.on_download_button_clicked)\n",
    "display(download_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e516ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- CELL 9 ---------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
